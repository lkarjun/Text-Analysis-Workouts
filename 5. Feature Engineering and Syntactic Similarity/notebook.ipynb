{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d571c92",
   "metadata": {},
   "source": [
    "## Bag-of-Words Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b02b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b235209",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"It was the best of times\",\n",
    "\"it was the worst of times\",\n",
    "\"it was the age of wisdom\",\n",
    "\"it was the age of foolishness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea1beaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_sentences = sentences + \\\n",
    "[\"John likes to watch movies. Mary likes movies too.\",\n",
    "\"Mary also likes to watch football games.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a9a1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f684dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'also', 'best', 'foolishness', 'football', 'games', 'it', 'john', 'likes', 'mary', 'movies', 'of', 'the', 'times', 'to', 'too', 'was', 'watch', 'wisdom', 'worst']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d5ece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = cv.transform(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc69ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba019af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>also</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>it</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>was</th>\n",
       "      <th>watch</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  also  best  foolishness  football  games  it  john  likes  mary  \\\n",
       "0    0     0     1            0         0      0   1     0      0     0   \n",
       "1    0     0     0            0         0      0   1     0      0     0   \n",
       "2    1     0     0            0         0      0   1     0      0     0   \n",
       "3    1     0     0            1         0      0   1     0      0     0   \n",
       "4    0     0     0            0         0      0   0     1      2     1   \n",
       "5    0     1     0            0         1      1   0     0      1     1   \n",
       "\n",
       "   movies  of  the  times  to  too  was  watch  wisdom  worst  \n",
       "0       0   1    1      1   0    0    1      0       0      0  \n",
       "1       0   1    1      1   0    0    1      0       0      1  \n",
       "2       0   1    1      0   0    0    1      0       1      0  \n",
       "3       0   1    1      0   0    0    1      0       0      0  \n",
       "4       2   0    0      0   1    1    0      1       0      0  \n",
       "5       0   0    0      0   1    0    0      1       0      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dt.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba95b4",
   "metadata": {},
   "source": [
    "### Calculating Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4266d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29e9a6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19218451]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1 = [1,3,3,45,5,6,6,6]\n",
    "word2 = [2,3,54,5,6,2,4,5]\n",
    "\n",
    "cosine_similarity([word1], [word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d39dcce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.524142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524142</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  1.000000  0.833333  0.666667  0.666667  0.000000  0.000000\n",
       "1  0.833333  1.000000  0.666667  0.666667  0.000000  0.000000\n",
       "2  0.666667  0.666667  1.000000  0.833333  0.000000  0.000000\n",
       "3  0.666667  0.666667  0.833333  1.000000  0.000000  0.000000\n",
       "4  0.000000  0.000000  0.000000  0.000000  1.000000  0.524142\n",
       "5  0.000000  0.000000  0.000000  0.000000  0.524142  1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cosine_similarity(dt, dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bdde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55cf62cc",
   "metadata": {},
   "source": [
    "## TF-IDF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f95c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47437625",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "\n",
    "tfidf_dt = tfidf.fit_transform(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b295b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>also</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>it</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>was</th>\n",
       "      <th>watch</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.56978</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.56978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.56978</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.56978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305609</td>\n",
       "      <td>0.501208</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.611219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.305609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419233</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.419233</td>\n",
       "      <td>0.419233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age      also     best  foolishness  football     games        it  \\\n",
       "0  0.000000  0.000000  0.56978      0.00000  0.000000  0.000000  0.338027   \n",
       "1  0.000000  0.000000  0.00000      0.00000  0.000000  0.000000  0.338027   \n",
       "2  0.467228  0.000000  0.00000      0.00000  0.000000  0.000000  0.338027   \n",
       "3  0.467228  0.000000  0.00000      0.56978  0.000000  0.000000  0.338027   \n",
       "4  0.000000  0.000000  0.00000      0.00000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.419233  0.00000      0.00000  0.419233  0.419233  0.000000   \n",
       "\n",
       "       john     likes      mary    movies        of       the     times  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.467228   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.467228   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.000000   \n",
       "4  0.305609  0.501208  0.250604  0.611219  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.343777  0.343777  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         to       too       was     watch   wisdom    worst  \n",
       "0  0.000000  0.000000  0.338027  0.000000  0.00000  0.00000  \n",
       "1  0.000000  0.000000  0.338027  0.000000  0.00000  0.56978  \n",
       "2  0.000000  0.000000  0.338027  0.000000  0.56978  0.00000  \n",
       "3  0.000000  0.000000  0.338027  0.000000  0.00000  0.00000  \n",
       "4  0.250604  0.305609  0.000000  0.250604  0.00000  0.00000  \n",
       "5  0.343777  0.000000  0.000000  0.343777  0.00000  0.00000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_dt.toarray(), columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abf3df17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675351</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675351</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.675351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.43076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.43076</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3        4        5\n",
       "0  1.000000  0.675351  0.457049  0.457049  0.00000  0.00000\n",
       "1  0.675351  1.000000  0.457049  0.457049  0.00000  0.00000\n",
       "2  0.457049  0.457049  1.000000  0.675351  0.00000  0.00000\n",
       "3  0.457049  0.457049  0.675351  1.000000  0.00000  0.00000\n",
       "4  0.000000  0.000000  0.000000  0.000000  1.00000  0.43076\n",
       "5  0.000000  0.000000  0.000000  0.000000  0.43076  1.00000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cosine_similarity(tfidf_dt, tfidf_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356518b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb9097a7",
   "metadata": {},
   "source": [
    "### ABC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32793d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_PATH = Path(\"../DATASETS/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb00a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = pd.read_csv(BASE_PATH/\"abcnews-date-text.csv.gz\", \n",
    "                        parse_dates=[\"publish_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e880a0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103663"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1ced6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date                                      headline_text\n",
       "0   2003-02-19  aba decides against community broadcasting lic...\n",
       "1   2003-02-19     act fire witnesses must be aware of defamation\n",
       "2   2003-02-19     a g calls for infrastructure protection summit\n",
       "3   2003-02-19           air nz staff in aust strike for pay rise"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a517fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c00b6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "636d43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "dt = tfidf.fit_transform(headlines['headline_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a2794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b25638f1",
   "metadata": {},
   "source": [
    "### Reducing Feature Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d392059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43dc002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b43f34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "print(len(STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0e467ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec05213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x95600 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5644186 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a968b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6d8bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "625f7be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\.virtualenvs\\Text-Analysis-workouts-4nsmzFq6\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1103663x58527 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5607113 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=STOP_WORDS, min_df=2)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84da8a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x24047 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5457800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=STOP_WORDS, min_df=1e-5)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11a34e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e59bc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\.virtualenvs\\Text-Analysis-workouts-4nsmzFq6\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1103663x71553 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 186386 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=STOP_WORDS, max_df=1e-5)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42225e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f618a3a3",
   "metadata": {},
   "source": [
    "## Improving Features by Making Then More Specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce49688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Linguistic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "975e5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3819eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
    "nouns_adjectives_verbs = ['NOUN', 'PROPN', 'ADJ', 'ADV', 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bfbaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d83f6910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999899it [1:13:24, 220.94it/s]C:\\Users\\HP\\.virtualenvs\\Text-Analysis-workouts-4nsmzFq6\\lib\\site-packages\\tqdm\\std.py:1180: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
      "  for obj in iterable:\n",
      "1103663it [1:21:24, 225.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm.tqdm(headlines.iterrows()):\n",
    "    doc = nlp(str(row[\"headline_text\"]))\n",
    "    headlines.at[i, \"lemmas\"] = \" \".join([token.lemma_ for token in doc])\n",
    "    headlines.at[i, \"nav\"] = \" \".join([token.lemma_ for token in doc\n",
    "         if token.pos_ in nouns_adjectives_verbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc039e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>nav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>aba decide against community broadcast licence</td>\n",
       "      <td>aba decide community broadcast licence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>act fire witness must be aware of defamation</td>\n",
       "      <td>act fire witness aware defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>a g call for infrastructure protection summit</td>\n",
       "      <td>g call infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>air nz staff aust strike pay rise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date                                      headline_text  \\\n",
       "0   2003-02-19  aba decides against community broadcasting lic...   \n",
       "1   2003-02-19     act fire witnesses must be aware of defamation   \n",
       "2   2003-02-19     a g calls for infrastructure protection summit   \n",
       "3   2003-02-19           air nz staff in aust strike for pay rise   \n",
       "\n",
       "                                           lemmas  \\\n",
       "0  aba decide against community broadcast licence   \n",
       "1    act fire witness must be aware of defamation   \n",
       "2   a g call for infrastructure protection summit   \n",
       "3        air nz staff in aust strike for pay rise   \n",
       "\n",
       "                                       nav  \n",
       "0   aba decide community broadcast licence  \n",
       "1        act fire witness aware defamation  \n",
       "2  g call infrastructure protection summit  \n",
       "3        air nz staff aust strike pay rise  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58172515",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines.to_csv(\"headlines.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51dc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
